{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b17f4c79-60c4-46e9-9754-b872dd3e05a5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-05T04:01:27.014202Z",
     "iopub.status.busy": "2025-04-05T04:01:27.013401Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-05 04:01:31.965875: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-04-05 04:01:32.647579: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-04-05 04:01:32.647691: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-04-05 04:01:32.757048: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-04-05 04:01:32.978816: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-04-05 04:01:34.646561: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Training Resnet18 CIFAR-10 model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/200: 100%|██████████| 157/157 [00:13<00:00, 11.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/200] - Train Loss: 2.2341, Train Acc: 25.86% | Val Loss: 1.7402, Val Acc: 35.73%\n",
      "New best model found at epoch 1 with Val Acc: 35.73%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/200: 100%|██████████| 157/157 [00:12<00:00, 12.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/200] - Train Loss: 1.5303, Train Acc: 43.49% | Val Loss: 1.4478, Val Acc: 46.84%\n",
      "New best model found at epoch 2 with Val Acc: 46.84%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/200: 100%|██████████| 157/157 [00:12<00:00, 12.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/200] - Train Loss: 1.2894, Train Acc: 53.26% | Val Loss: 1.2702, Val Acc: 54.28%\n",
      "New best model found at epoch 3 with Val Acc: 54.28%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/200: 100%|██████████| 157/157 [00:12<00:00, 12.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/200] - Train Loss: 1.0684, Train Acc: 61.71% | Val Loss: 1.1837, Val Acc: 60.05%\n",
      "New best model found at epoch 4 with Val Acc: 60.05%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/200: 100%|██████████| 157/157 [00:12<00:00, 12.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/200] - Train Loss: 0.8756, Train Acc: 69.19% | Val Loss: 1.0485, Val Acc: 63.94%\n",
      "New best model found at epoch 5 with Val Acc: 63.94%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/200: 100%|██████████| 157/157 [00:12<00:00, 12.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/200] - Train Loss: 0.7371, Train Acc: 73.64% | Val Loss: 0.8699, Val Acc: 69.44%\n",
      "New best model found at epoch 6 with Val Acc: 69.44%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/200: 100%|██████████| 157/157 [00:12<00:00, 12.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/200] - Train Loss: 0.6164, Train Acc: 78.35% | Val Loss: 0.7827, Val Acc: 72.80%\n",
      "New best model found at epoch 7 with Val Acc: 72.80%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/200: 100%|██████████| 157/157 [00:12<00:00, 12.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/200] - Train Loss: 0.5185, Train Acc: 81.40% | Val Loss: 0.7995, Val Acc: 72.28%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/200: 100%|██████████| 157/157 [00:12<00:00, 12.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/200] - Train Loss: 0.4121, Train Acc: 85.32% | Val Loss: 0.8971, Val Acc: 70.38%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/200: 100%|██████████| 157/157 [00:12<00:00, 12.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/200] - Train Loss: 0.3248, Train Acc: 88.46% | Val Loss: 0.7748, Val Acc: 74.83%\n",
      "New best model found at epoch 10 with Val Acc: 74.83%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/200: 100%|██████████| 157/157 [00:12<00:00, 12.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [11/200] - Train Loss: 0.2632, Train Acc: 90.83% | Val Loss: 0.7953, Val Acc: 75.30%\n",
      "New best model found at epoch 11 with Val Acc: 75.30%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12/200: 100%|██████████| 157/157 [00:12<00:00, 12.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [12/200] - Train Loss: 0.2126, Train Acc: 92.63% | Val Loss: 0.7732, Val Acc: 75.81%\n",
      "New best model found at epoch 12 with Val Acc: 75.81%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13/200: 100%|██████████| 157/157 [00:12<00:00, 12.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [13/200] - Train Loss: 0.1646, Train Acc: 94.36% | Val Loss: 1.0608, Val Acc: 71.74%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14/200: 100%|██████████| 157/157 [00:12<00:00, 12.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [14/200] - Train Loss: 0.1592, Train Acc: 94.50% | Val Loss: 0.9517, Val Acc: 75.09%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15/200: 100%|██████████| 157/157 [00:12<00:00, 12.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [15/200] - Train Loss: 0.1316, Train Acc: 95.38% | Val Loss: 0.7968, Val Acc: 78.30%\n",
      "New best model found at epoch 15 with Val Acc: 78.30%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16/200: 100%|██████████| 157/157 [00:12<00:00, 12.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [16/200] - Train Loss: 0.1029, Train Acc: 96.41% | Val Loss: 1.3036, Val Acc: 70.53%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17/200: 100%|██████████| 157/157 [00:12<00:00, 12.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [17/200] - Train Loss: 0.1319, Train Acc: 95.46% | Val Loss: 0.8709, Val Acc: 76.66%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18/200: 100%|██████████| 157/157 [00:12<00:00, 12.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [18/200] - Train Loss: 0.1059, Train Acc: 96.43% | Val Loss: 0.9628, Val Acc: 75.81%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19/200: 100%|██████████| 157/157 [00:12<00:00, 12.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [19/200] - Train Loss: 0.0991, Train Acc: 96.59% | Val Loss: 0.9444, Val Acc: 75.70%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20/200: 100%|██████████| 157/157 [00:12<00:00, 12.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [20/200] - Train Loss: 0.1032, Train Acc: 96.42% | Val Loss: 1.0008, Val Acc: 75.42%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 21/200: 100%|██████████| 157/157 [00:12<00:00, 12.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [21/200] - Train Loss: 0.1119, Train Acc: 96.20% | Val Loss: 0.9278, Val Acc: 75.51%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 22/200: 100%|██████████| 157/157 [00:12<00:00, 12.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [22/200] - Train Loss: 0.1020, Train Acc: 96.53% | Val Loss: 0.8464, Val Acc: 77.59%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 23/200: 100%|██████████| 157/157 [00:12<00:00, 12.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [23/200] - Train Loss: 0.1057, Train Acc: 96.35% | Val Loss: 0.9893, Val Acc: 74.89%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 24/200: 100%|██████████| 157/157 [00:12<00:00, 12.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [24/200] - Train Loss: 0.0848, Train Acc: 97.21% | Val Loss: 0.8826, Val Acc: 77.36%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 25/200: 100%|██████████| 157/157 [00:12<00:00, 12.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [25/200] - Train Loss: 0.0934, Train Acc: 96.82% | Val Loss: 1.0234, Val Acc: 74.58%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 26/200: 100%|██████████| 157/157 [00:12<00:00, 12.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [26/200] - Train Loss: 0.1189, Train Acc: 95.98% | Val Loss: 0.7809, Val Acc: 78.38%\n",
      "New best model found at epoch 26 with Val Acc: 78.38%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 27/200: 100%|██████████| 157/157 [00:12<00:00, 12.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [27/200] - Train Loss: 0.0750, Train Acc: 97.53% | Val Loss: 0.7732, Val Acc: 79.04%\n",
      "New best model found at epoch 27 with Val Acc: 79.04%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 28/200: 100%|██████████| 157/157 [00:12<00:00, 12.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [28/200] - Train Loss: 0.0721, Train Acc: 97.63% | Val Loss: 0.9619, Val Acc: 76.02%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 29/200: 100%|██████████| 157/157 [00:12<00:00, 12.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [29/200] - Train Loss: 0.1031, Train Acc: 96.52% | Val Loss: 1.0732, Val Acc: 74.55%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 30/200: 100%|██████████| 157/157 [00:12<00:00, 12.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [30/200] - Train Loss: 0.0816, Train Acc: 97.28% | Val Loss: 0.9120, Val Acc: 77.10%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 31/200: 100%|██████████| 157/157 [00:12<00:00, 12.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [31/200] - Train Loss: 0.0939, Train Acc: 96.80% | Val Loss: 0.9930, Val Acc: 74.59%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 32/200:  52%|█████▏    | 81/157 [00:06<00:06, 12.36it/s]"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.models as models\n",
    "import io\n",
    "from contextlib import redirect_stdout\n",
    "from PIL import Image\n",
    "from torch.utils.data import Subset, Dataset, random_split\n",
    "from tqdm import tqdm\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "# ----- Define a Tee class to write to multiple streams -----\n",
    "class Tee(object):\n",
    "    def __init__(self, *fileobjects):\n",
    "        self.fileobjects = fileobjects\n",
    "\n",
    "    def write(self, text):\n",
    "        for f in self.fileobjects:\n",
    "            f.write(text)\n",
    "            f.flush()\n",
    "\n",
    "    def flush(self):\n",
    "        for f in self.fileobjects:\n",
    "            f.flush()\n",
    "\n",
    "# ----- Specify paths for saving logs, metrics, and models -----\n",
    "log_file_path = \"./logs/cifar10_training_log.txt\"\n",
    "metrics_file_path = \"./metrics/cifar10_training_metrics.json\"\n",
    "best_model_path = \"./models/cifar10_best_model\"\n",
    "save_path = \"./models/cifar10_resnet18\"\n",
    "\n",
    "# ----- Prepare the CIFAR-10 DataLoaders -----\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "# Download and prepare datasets\n",
    "full_trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                            download=True, transform=transform)\n",
    "\n",
    "# Define the sizes for train and validation sets\n",
    "train_size = int(0.8 * len(full_trainset))  # 80% for training\n",
    "val_size = len(full_trainset) - train_size   # Remaining 20% for validation\n",
    "\n",
    "# Split the dataset\n",
    "trainset, valset = random_split(full_trainset, [train_size, val_size])\n",
    "\n",
    "# Download and load the test dataset\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                      download=True, transform=transform)\n",
    "\n",
    "batch_size = 256\n",
    "num_workers = 2\n",
    "train_loader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
    "                                         shuffle=True, num_workers=num_workers)\n",
    "val_loader = torch.utils.data.DataLoader(valset, batch_size=batch_size,\n",
    "                                       shuffle=False, num_workers=num_workers)\n",
    "test_loader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n",
    "                                        shuffle=False, num_workers=num_workers)\n",
    "\n",
    "\n",
    "\n",
    "# ----- Prepare the Model for CIFAR-10 -----\n",
    "model = models.resnet18(weights=None)\n",
    "# Adjust first layer for 32x32 images: replace 7x7 conv with 3x3 and remove maxpool\n",
    "model.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "model.maxpool = nn.Identity()\n",
    "# Change final layer for 10 classes (CIFAR-10) instead of 200 (Tiny ImageNet)\n",
    "num_ftrs = model.fc.in_features\n",
    "model.fc = nn.Linear(num_ftrs, 10)\n",
    "\n",
    "# ----- Setup Training Parameters -----\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "num_epochs = 200\n",
    "learning_rate = 0.1\n",
    "checkpoint_frequency = 10\n",
    "start_epoch = 0\n",
    "start_checkpoint = None\n",
    "\n",
    "# If starting from a checkpoint, load the model state\n",
    "if start_checkpoint:\n",
    "    state_dict = torch.load(start_checkpoint, map_location=device)\n",
    "    model.load_state_dict(state_dict)\n",
    "\n",
    "model.to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=learning_rate, momentum=0.9, weight_decay=5e-4)\n",
    "\n",
    "# ----- Initialize Metrics Storage -----\n",
    "metrics = {\n",
    "    \"epochs\": [],\n",
    "    \"train_loss\": [],\n",
    "    \"train_acc\": [],\n",
    "    \"val_loss\": [],\n",
    "    \"val_acc\": []\n",
    "}\n",
    "best_val_acc = 0.0\n",
    "best_epoch = None\n",
    "\n",
    "# ----- Capture Standard Output During Training and Print to Console -----\n",
    "log_capture = io.StringIO()\n",
    "tee = Tee(sys.stdout, log_capture)  # This will print to stdout and also capture the output\n",
    "\n",
    "# Add before training loop starts\n",
    "writer = SummaryWriter(log_dir='./runs/cifar10_experiment')\n",
    "\n",
    "with redirect_stdout(tee):\n",
    "    print(\"Training Resnet18 CIFAR-10 model...\")\n",
    "    for epoch in range(start_epoch, start_epoch + num_epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "\n",
    "        # Save a checkpoint at the specified frequency\n",
    "        if epoch % checkpoint_frequency == 0:\n",
    "            torch.save(model.state_dict(), save_path + \"_\" + str(epoch) + \".pth\")\n",
    "\n",
    "        # Modified training loop with tqdm\n",
    "        for inputs, labels in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs}\"):\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += labels.size(0)\n",
    "            correct += predicted.eq(labels).sum().item()\n",
    "\n",
    "        train_epoch_loss = running_loss / total\n",
    "        train_epoch_acc = 100. * correct / total\n",
    "\n",
    "        # Evaluate on the validation set\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        val_correct = 0\n",
    "        val_total = 0\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in val_loader:\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_loss += loss.item() * inputs.size(0)\n",
    "                _, predicted = outputs.max(1)\n",
    "                val_total += labels.size(0)\n",
    "                val_correct += predicted.eq(labels).sum().item()\n",
    "\n",
    "        val_epoch_loss = val_loss / val_total\n",
    "        val_epoch_acc = 100. * val_correct / val_total\n",
    "\n",
    "        # Store metrics for this epoch\n",
    "        metrics[\"epochs\"].append(epoch+1)  # Epochs are stored 1-indexed for clarity\n",
    "        metrics[\"train_loss\"].append(train_epoch_loss)\n",
    "        metrics[\"train_acc\"].append(train_epoch_acc)\n",
    "        metrics[\"val_loss\"].append(val_epoch_loss)\n",
    "        metrics[\"val_acc\"].append(val_epoch_acc)\n",
    "\n",
    "        print(f\"Epoch [{epoch+1}/{start_epoch + num_epochs}] - Train Loss: {train_epoch_loss:.4f}, Train Acc: {train_epoch_acc:.2f}% | Val Loss: {val_epoch_loss:.4f}, Val Acc: {val_epoch_acc:.2f}%\")\n",
    "\n",
    "        # Add TensorBoard logging after computing metrics\n",
    "        writer.add_scalar('Loss/Train', train_epoch_loss, epoch)\n",
    "        writer.add_scalar('Accuracy/Train', train_epoch_acc, epoch)\n",
    "        writer.add_scalar('Loss/Validation', val_epoch_loss, epoch)\n",
    "        writer.add_scalar('Accuracy/Validation', val_epoch_acc, epoch)\n",
    "\n",
    "        # Save the best model based on validation accuracy\n",
    "        if val_epoch_acc > best_val_acc:\n",
    "            best_val_acc = val_epoch_acc\n",
    "            best_epoch = epoch+1\n",
    "            torch.save(model.state_dict(), best_model_path)\n",
    "            print(f\"New best model found at epoch {epoch+1} with Val Acc: {val_epoch_acc:.2f}%\")\n",
    "        \n",
    "        # ----- Save metrics JSON after every epoch -----\n",
    "        with open(metrics_file_path, \"w\") as f:\n",
    "            json.dump(metrics, f, indent=4)\n",
    "    \n",
    "    print(\"Training complete.\")\n",
    "    torch.save(model.state_dict(), save_path + \"_final.pth\")\n",
    "\n",
    "# Close the TensorBoard writer\n",
    "writer.close()\n",
    "\n",
    "# Write the captured logs to the specified log file (log_capture already contains the output)\n",
    "with open(log_file_path, \"w\") as f:\n",
    "    f.write(log_capture.getvalue())\n",
    "\n",
    "# Optionally, print confirmation that the logs, metrics, and best model have been saved\n",
    "print(\"Training log captured and saved to\", log_file_path)\n",
    "print(\"Training metrics saved to\", metrics_file_path)\n",
    "print(\"Best model saved from epoch\", best_epoch, \"with validation accuracy of\", best_val_acc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
